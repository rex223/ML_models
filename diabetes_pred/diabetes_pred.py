# -*- coding: utf-8 -*-
"""diabetes_pred.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19g7rmLo3XuC0fyOFrLq16yiD9VDDx0nv
"""

# !pip install scikit-fuzzy

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn import svm
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from imblearn.combine import SMOTETomek
import pickle
from xgboost import XGBClassifier
import matplotlib.pyplot as plt
from sklearn.ensemble import VotingClassifier
import skfuzzy as fuzz
import skfuzzy.control as ctrl

# !pip install streamlit

import numpy as np
import sklearn
import imblearn
import xgboost
import matplotlib
import skfuzzy

print("NumPy:", np.__version__)
print("Scikit-learn:", sklearn.__version__)
print("imblearn:", imblearn.__version__)
print("xgboost:", xgboost.__version__)
print("matplotlib:", matplotlib.__version__)
print("scikit-fuzzy:", skfuzzy.__version__)

# Load dataset
df = pd.read_csv('/content/diabetes.csv')
print(df.head())
# Handle categorical features
categorical_cols = ['gender', 'hypertension', 'heart_disease', 'smoking_history']
df[categorical_cols] = df[categorical_cols].astype(str)
df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)

#save the features
with open('features.pkl','wb') as file:
  pickle.dump(df.columns,file)

"""#implementing a fuzzy system for handling uncertainty"""

# Define fuzzy variables
hba1c = ctrl.Antecedent(np.arange(3, 15, 0.1), 'HbA1c_level')
bmi = ctrl.Antecedent(np.arange(10, 50, 0.1), 'bmi')
glucose = ctrl.Antecedent(np.arange(50, 300, 1), 'blood_glucose_level')
risk = ctrl.Consequent(np.arange(0, 1.1, 0.1), 'diabetes_risk')
hypertension_range = np.arange(0, 1.1, 0.1)
hypertension_fuzzy = ctrl.Antecedent(hypertension_range, 'hypertension')
smoking_range = np.arange(0, 1.1, 0.1)
smoking_fuzzy = ctrl.Antecedent(smoking_range, 'smoking')

#Define fuzzy sets (Low, Medium, High)
hba1c.automf(3)
bmi.automf(3)
glucose.automf(3)
risk.automf(3)
#Defining fuzzy set for categorical data
hypertension_fuzzy['absent'] = fuzz.trimf(hypertension_fuzzy.universe, [0, 0, 0.5])
hypertension_fuzzy['present'] = fuzz.trimf(hypertension_fuzzy.universe, [0.5, 1, 1])
smoking_fuzzy['never'] = fuzz.trimf(smoking_fuzzy.universe, [0, 0, 0.3])
smoking_fuzzy['former'] = fuzz.trimf(smoking_fuzzy.universe, [0.2, 0.5, 0.8])
smoking_fuzzy['current'] = fuzz.trimf(smoking_fuzzy.universe, [0.7, 1, 1])

# Example fuzzy rules that incorporate all factors:
rule1 = ctrl.Rule(hba1c['good'] & bmi['good'] & hypertension_fuzzy['present'] & smoking_fuzzy['current'], risk['good'])
rule2 = ctrl.Rule(hba1c['average'] & glucose['average'] & hypertension_fuzzy['absent'] & smoking_fuzzy['former'], risk['average'])
rule3 = ctrl.Rule(hba1c['poor'] & glucose['poor'] & hypertension_fuzzy['absent'] & smoking_fuzzy['never'], risk['poor'])

# Create fuzzy control system
risk_ctrl = ctrl.ControlSystem([rule1, rule2, rule3])
risk_sim = ctrl.ControlSystemSimulation(risk_ctrl)

#saving the fuzzy model
with open("fuzzy.pkl", "wb") as file:
    pickle.dump(risk_ctrl, file)

# Features and target
x = df.drop(columns=['diabetes'], axis=1)
y = df['diabetes']

print(x.shape,y.shape)

#finding missing values
df.isnull().sum()

df.value_counts(['diabetes'])

"""#our dataset is highly imbalanced so we correct it first"""

# Apply SMOTE + Tomek Links
smote_tomek = SMOTETomek(sampling_strategy=1.0, random_state=42)
x_resampled, y_resampled = smote_tomek.fit_resample(x, y)

print("Class distribution after SMOTE:\n", pd.Series(y_resampled).value_counts())

print(x_resampled.shape,y_resampled.shape)

"""#standardizing and normalizing data"""

# Normalize HbA1c separately
x_resampled['HbA1c_level'] = (x_resampled['HbA1c_level'] - x_resampled['HbA1c_level'].min()) / (x_resampled['HbA1c_level'].max() - x_resampled['HbA1c_level'].min())

# Standardizing
scaler = StandardScaler()
x_scaled = scaler.fit_transform(x_resampled)

# Saving the scaler
with open('scaler.pkl', 'wb') as scaler_file:
    pickle.dump(scaler, scaler_file)

"""#splitting the dataset in test and train data"""

# Splitting the dataset
x_train, x_test, y_train, y_test = train_test_split(x_scaled, y_resampled, test_size=0.2, stratify=y_resampled, random_state=43)

"""#hyperparameter tuning"""

# Hyperparameter tuning for SVM
param_grid = {
    'C': [1, 10],
    'gamma': ['scale', 0.1, 1, 10]
}

grid = RandomizedSearchCV(
    svm.SVC(kernel='rbf'),
    param_distributions=param_grid,
    n_iter=5,
    cv=2,
    scoring='accuracy',
    verbose=1,
    n_jobs=-1,
    random_state=42
)

grid.fit(x_train[:20000], y_train[:20000])
best_params = grid.best_params_
print("✅ Best SVM Parameters:", best_params)

"""#training and testing"""

# Train SVM model with best params and non linear kernel
classifier = svm.SVC(kernel='rbf', C=best_params['C'], gamma=best_params['gamma'])

classifier.fit(x_train, y_train)

"""normal prediction after hyperparameter tuning"""

# Save the trained model
with open('model.pkl', 'wb') as model_file:
    pickle.dump(classifier, model_file)

# Model evaluation
y_train_pred = classifier.predict(x_train)
y_test_pred = classifier.predict(x_test)

# Training and Testing Accuracy
train_acc = accuracy_score(y_train, y_train_pred)
test_acc = accuracy_score(y_test, y_test_pred)

print(f"Training Accuracy: {100*train_acc:.5f} %")
print(f"Testing Accuracy: {100*test_acc:.5f} %")

# Test predictions before saving
sample_inputs = x_test[:10]
sample_preds = classifier.predict(sample_inputs)

print("Sample Predictions:", sample_preds)
print("Actual Labels:     ", y_test[:10].values)

from sklearn.metrics import classification_report, confusion_matrix

# Evaluate on test data
print("Classification Report:\n", classification_report(y_test, y_test_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_test_pred))

"""#Using gradient boosting

"""

# Train XGBoost model
xgb_classifier = XGBClassifier(n_estimators=600, max_depth=7, learning_rate=0.05,
                               subsample=0.8, colsample_bytree=0.7,
                               gamma=1.15,random_state=9)
xgb_classifier.fit(x_train, y_train)

#Saving the classifier
with open("xgb_model.pkl", "wb") as file:
    pickle.dump(xgb_classifier, file)  # Assuming xgb_classifier is your trained model

# Evaluating XGBoost accuracy
y_train_pred_xgb = xgb_classifier.predict(x_train)
y_test_pred_xgb = xgb_classifier.predict(x_test)

train_acc_xgb = accuracy_score(y_train, y_train_pred_xgb)
test_acc_xgb = accuracy_score(y_test, y_test_pred_xgb)

print(f"XGBoost Training Accuracy: {100*train_acc_xgb:.5f} %")
print(f"XGBoost Testing Accuracy: {100*test_acc_xgb:.5f} %")

# Adjusting decision threshold
y_probs = xgb_classifier.predict_proba(x_test)[:, 1]

# Set your decision threshold here (default is 0.5, change as needed)
threshold = 0.25

# Generate predictions based on the new threshold
y_pred_adjusted = (y_probs > threshold).astype(int)

# Evaluate the model using the adjusted predictions
from sklearn.metrics import confusion_matrix, accuracy_score
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_adjusted))
print("Adjusted Accuracy:", accuracy_score(y_test, y_pred_adjusted))

"""CHECKING HOW OUR MODEL IS DEPENDENT ON FEATURES THROUGH A VISUAL REPRESENTATION"""

# Check feature importance in XGBoost
feature_importance = pd.Series(xgb_classifier.feature_importances_, index=x.columns)
feature_importance.sort_values(ascending=False).plot(kind='bar', figsize=(10,5), title="Feature Importance")
plt.show()

"""CHECKING OUR MODEL"""



# Test predictions before saving
sample_inputs = x_test[:10]
sample_preds = classifier.predict(sample_inputs)

print("Sample Predictions:", sample_preds)
print("Actual Labels     :", y_test[:10].values)

import pickle

# Load the XGBoost model
with open("xgb_model.pkl", "rb") as f:
    xgb_model = pickle.load(f)
print("✅ XGBoost Model Loaded Successfully")

# Load the Fuzzy system
with open("fuzzy.pkl", "rb") as f:
    fuzzy_system = pickle.load(f)
print("✅ Fuzzy System Loaded Successfully")